\section{Standard BitTorrent Study}

\subsection{Experimental Setup}

In this section, we will study two types of swarms and compare the
performance of each when using local knowledge, global knowledge or 
omniscience for the rarest piece selection algorithm. The difference
between global knowledge and omnisience is that nodes with global
knowledge know which pieces every node in the swarm has but they do
no not know which pieces those nodes are currently
requesting. Omniscient nodes know both what every peer is requesting
and what they have. This allows for very efficient next piece
selection but is impossible without some form of gossip since requests
are only sent to one node whereas have messages are sent to all of a
node's peers. The goal of this section is to explore the potential for
a gossip algorithm to improve BitTorrent. The first set of simulations
use swarms that start with a single seed and a number of leechers.
The seed is altruistic and therefore will stay the entire time. This 
simulates a ``healthy'' swarm that will not die, but may benefit from 
better replication of pieces. The second type is a swarm with no seeders, 
although a complete copy of the file exists within the swarm between a
few nodes. This simulates a situation in which the seeders have left
and a swarm is in an ``unhealthy'' state. None of the nodes are
altruistic and therefore leave as soon as possible. For this swarm,
there are two goals. The primary goal is to simply make sure the swarm
survives, because it is possible for a node to leave with pieces that
only it holds, which means no other node can complete. The second goal
is, if the swarm survives, can global knowledge or omniscience improve 
performance.

For all of the experiments below, we are assuming the swarm is sharing a
40 MB file divided into 1000 pieces. All leechers have a download rate
selected from a uniform distribution between 50 and 100 KB/s, which is
approximately what a DSL user can achieve in a typical swarm. Finally, all
leechers will join at a random time in the first 100 seconds of the swarm.

The measurements taken for each experiment are simply the download times for
each node in the swarm if the swarms survives to completion or the
number of nodes that are stranded if the swarm dies. We considered
other methods such as metrics to evaluate local vs. global knowledge,
such as a distance metric comparing the list of pieces sorted by
rarity within the peer set vs. rarity globally, but decided that such
metrics were fairly artibtrary and the node download times tell us
what we actually care about: will global knowledge improve a swarm's
performance?

\subsection{Swarms with Seeders}

In this section, we will examine swarms with a single seeder at the beginning
and a number of leechers that join in the first 100 seconds. To ensure
that a diverse set of conditions are studied, the number of nodes in the swarm, 
number of peers per node, and the initial seeder's upload rate will be varied.
In the healthiest swarms with a seeder, there should be many nodes, many peers per node, and
a high seeder upload rate. Likewise, the least healthy swarms have fewer nodes,
fewer peers per node, and a lower upload rate for the seeder. However, if too fewer
nodes exist than the peers allowed per node, then each node will have perfect global
knowledge by default, therefore, the number of nodes must always be kept above
the number of peers per node. 

% Variables:
% Number of nodes: 100, 200
% Number of peers: 10/20, 20/30, 30/40 (desired/max)
% Seed upload rate: 60, 80, 100

% Experiments (local vs global for each):
% (100, 10, 100) L = 1780, 1533 G = 2040, 1734
% (100, 20, 100) L = 1650, 1345 G = 1700, 1429
% (100, 30, 100) L = 1550, 1396 G = 1720, 1368

% (200, 30, 100) L = 1950, 1478 G = 2060, 1565

% (100, 10, 80)  L = 2430, 2256 G = 2500, 2245


% Table 1:
% nodes, peers, rate, local total runtime, local average download time, global total runtime, global average download time

Table X shows the results for a number of simulations with a single
seeder. The key takeaway for all of the data above seems to be that there
is very little difference in performance between using the peer set or the
global node set for the rarest first piece selection algorithm. Sometimes
local knowledge is better and sometimes global knowledge is better,
but not in any statistically significant fashion. All of the various
scenarios tested above, including slowing down the seeder, decreasing
the number of peers, etc. all showed this same basic pattern. This means
that even if we had an absolutely perfect gossip algorithm, it would do
very little to help improve the performance of these swarms.

Other observations from this data include some obvious things such as
if the seeder's upload rate is decreased, the overall swarm has a much
longer download time. This makes sense because the seeder's upload rate
is divided five ways between its unchoked peers, so it will take more
time for the first copy of pieces to get out into the network and be
replicated. We also ran some even slower seeders such as an as uprate
of 20 that were not finishing in any reasonable amount of time so we
did not collect the run times. One interesting result was that even if
the numer of nodes doubles, the performance penalty for node downloading
was essentially negligible. This shows that BitTorrent scales very well
assuming the initial seeder can get the pieces replicated.  We can also
see that as the number of peers increases, performance improves somewhat
going from 10 to 20 peers, but seems to reach diminishing returns going
from 20 to 30 peers. This is likely the result the faster nodes to
finding each other and making replicas faster.



\subsection{Swarms with No Seeders}

The primariy goal of this research, however, was not to improve
performance in healthy swarms but to prevent the death of unhealthy
swarms. To determine how effective the existing local knowledge
implementation of BitTorrent was as dealing with this situation we
created a special swarm with no seed. Instead the a single copy of
each piece was spread between four nodes which would leave promptly
upon completing the entire file. This created the situation where the
swarm had to create copies of all of the critical pieces before any of
the four critical nodes left the swarm. This kind of swarm also
resembles a swarm that has experienced flash crowd behavior where a
large number of nodes joined completed the file and then left. The
four nodes that start this simulation would then be the remainder of
that initial flash crowd while the new nodes joining would represent
the steady stream of nodes that often join after a flash crowd. For
more information on this behavior in torrents, please see 
``The Bittorrent  P2P File-Sharing System: Measurements and Analysis''
(**CITE HERE**). 

Using this ``unheatly'' swarm simulation setup we then ran the
simulation five times for the three levels of node knowledge discussed
in section 4.1: local knowledge, global knowledge and
omniscience. Five runs were performed for each level of knowledge
because the probibalistic distribution of pieces and upload/download
rates sometimes produced swarms that could not fail or swarms that
could not be saved. This can be seen in the failure that occured even
with omniscient nodes. Swarms which survived finished the simulation
with a single node remaining. Among those swarms which did not survive
the degree of piece replication efficiency can be seen in how many
nodes were stranded. The swarms with fewer peers remaining managed to
replicate the pieces more efficiently and thereby extended the
lifetime of the torrent. The results from all five runs for each type
of node knowledge are presented in Table X.

%variables global, local or omniscient knowledge
%Table
%    Runs       | 1 | 2 | 3 | 4 | 5 | 1  | 2  | 3  | 4  | 5  |
%Knowledge Type |  nodes stranded   |     average times      |
%    local      | 99|  2| 99| 99| 99|1387|2540|1710|2019|1433|
%    global     | 99| 99| 99| 99| 46|1850|1464|1369|1535|2391|
%    omniscient |  1|  2|  2| 99|  2|1711|2370|1646|1465|2386|

%Knowledge Type | average nodes stranded  |   average time   |
%    local      |          80             |        1818      |
%    global     |          88             |        1727      |
%    omniscient |          21             |        1916      |


From the results in Table X we can see that omniscient node knowledge
represents a optimal maximum for the efficiency of piece
replication. Interestingly global knowledge performed worse than local
knowledge in terms of efficient piece replication. This is because the
global view of the swarms causes the node with global knowledge to all
download the same piece from the critical nodes so many copies are
created of one critically rare piece while other critically rare
pieces aren't copied at all. The local knowledge nodes were therefore
more efficient because their notion of the rarest piece was more
diverse. This lead them to replicate different pieces and achieve more
efficeint replication overall. The primary conclusion to be drawn from
these results is, therefore, that while local knowledge can
occationally save a swarm, a more intelligent piece replication scheme
would be more effective. This opens the door for BitTorrent gossip to
achieve real gains over the traditional implementation by extending
the lifetime of the torrent in extreme situations.

Describe the NO\_SEED test and give results.
