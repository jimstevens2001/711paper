\section{Standard BitTorrent Study}

\subsection{Experimental Setup}

In this section, we will study two types of swarms and compare the
performance of each when using local knowledge or global knowledge for
the rarest piece selection algorithm. The goal of this section is to
explore the potential for a gossip algorithm to improve BitTorrent.
The first type is a swarm that starts with a single seed and a number
of leechers.  The seed is altruistic and therefore will stay the entire
time. This simulates a ``healthy'' swarm that will not die, but may benefit
from better replication of pieces. The second type is a swarm with no
seeders, although a complete copy of the file exists within the swarm
between a few nodes. This simulates a situation in which the seeders
have left and a swarm is in an ``unhealthy'' state. None of the nodes
are altruistic and therefore leave as soon as possible. For this swarm,
there are two goals. The primary goal is to simply make sure the swarm
survives, because it is possible for a node to leave with pieces that
only it holds, which means no other node can complete. The second goal
is, if the swarm survives, can global knowledge improve performance.

For all of the experiments below, we are assuming the swarm is sharing a
40 MB file divided into 1000 pieces. All leechers have a download rate
selected from a uniform distribution between 50 and 100 KB/s, which is
approximately what a DSL user can achieve in a typical swarm. Finally, all
leechers will join at a random time in the first 100 seconds of the swarm.

The measurements taken for each experiment are simply the download times for
each node in the swarm. We considered other methods such as metrics to
evaluate local vs. global knowledge, such as a distance metric comparing the 
list of pieces sorted by rarity within the peer set vs. rarity globally, but
decided that such metrics were fairly artibtrary and the node download times
tell us what we actually care about: will global knowledge improve a swarm's
performance?

\subsection{Swarms with Seeders}

In this section, we will examine swarms with a single seeder at the beginning
and a number of leechers that join in the first 100 seconds. To ensure
that a diverse set of conditions are studied, the number of nodes in the swarm, 
number of peers per node, and the initial seeder's upload rate will be varied.
In the healthiest swarms with a seeder, there should be many nodes, many peers per node, and
a high seeder upload rate. Likewise, the least healthy swarms have fewer nodes,
fewer peers per node, and a lower upload rate for the seeder. However, if too fewer
nodes exist than the peers allowed per node, then each node will have perfect global
knowledge by default, therefore, the number of nodes must always be kept above
the number of peers per node. 

% Variables:
% Number of nodes: 100, 200
% Number of peers: 10/20, 20/30, 30/40 (desired/max)
% Seed upload rate: 60, 80, 100

% Experiments (local vs global for each):
% (100, 10, 100) L = 1780, 1533 G = 2040, 1734
% (100, 20, 100) L = 1650, 1345 G = 1700, 1429
% (100, 30, 100) L = 1550, 1396 G = 1720, 1368

% (200, 30, 100) L = 1950, 1478 G = 2060, 1565

% (100, 10, 80)  L = 2430, 2256 G = 2500, 2245


% Table 1:
% nodes, peers, rate, local total runtime, local average download time, global total runtime, global average download time

Table X shows the results for a number of simulations with a single
seeder. The key takeaway for all of the data above seems to be that there
is very little difference in performance between using the peer set or the
global node set for the rarest first piece selection algorithm. Sometimes
local knowledge is better and sometimes global knowledge is better,
but not in any statistically significant fashion. All of the various
scenarios tested above, including slowing down the seeder, decreasing
the number of peers, etc. all showed this same basic pattern. This means
that even if we had an absolutely perfect gossip algorithm, it would do
very little to help improve the performance of these swarms.

Other observations from this data include some obvious things such as
if the seeder's upload rate is decreased, the overall swarm has a much
longer download time. This makes sense because the seeder's upload rate
is divided five ways between its unchoked peers, so it will take more
time for the first copy of pieces to get out into the network and be
replicated. We also ran some even slower seeders such as an as uprate
of 20 that were not finishing in any reasonable amount of time so we
did not collect the run times. One interesting result was that even if
the numer of nodes doubles, the performance penalty for node downloading
was essentially negligible. This shows that BitTorrent scales very well
assuming the initial seeder can get the pieces replicated.  We can also
see that as the number of peers increases, performance improves somewhat
going from 10 to 20 peers, but seems to reach diminishing returns going
from 20 to 30 peers. This is likely the result the faster nodes to
finding each other and making replicas faster.



\subsection{Swarms with No Seeders}

The primariy goal of this research, however, was not to improve performance in
healthy swarms but to prevent the death of unhealthy swarms. The existence of the
99\% problem seems to indicate that it is a common occurance in the real world for
a seed or a set of peers to leave abruptly and strand the swarm with no copies of certain
pieces. In these situations it might have been possible for the swarm to survive if the nodes
in that swarm had efficiently duplicated every piece at least once in the swarm. To determine
how effective the existing local knowledge implementation of BitTorrent was as dealing with
this situation we created a special swarm with no seed. Instead the a single copy of each piece
was spread between four nodes which would leave promptly upon completing the entire file. This
created the situation where the swarm had to create copies of all of the critical pieces 
before any of the four critical nodes left the swarm. This kind of swarm also resembles a
swarm that has experienced flash crowd behavior where a large number of nodes joined completed
the file and then left. The four nodes that start this simulation would then be the remainder of
that initial flash crowd while the new nodes joining would represent the steady stream of nodes
that often join after a flash crowd. For more information on this behavior in torrents, please
see ``The Bittorrent P2P File-Sharing System: Measurements and Analysis'' (**CITE HERE**). 

Using this ``unheatly'' swarm simulation setup we then ran the simulation five times for the 
following levels of node knowledge: local knowledge, global knowledge and omniscience. 


Describe the NO\_SEED test and give results.
